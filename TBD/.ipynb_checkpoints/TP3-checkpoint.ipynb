{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-complement",
   "metadata": {},
   "source": [
    "# TP3 : Fenêtres de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-moment",
   "metadata": {},
   "source": [
    "Maintenant que vous êtes des experts en estimation de gaussiennes, on va découvrir une nouvelle technique pour la classification : les fenêtres de Parzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "# Import de vos fonctions\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-yellow",
   "metadata": {},
   "source": [
    "Contrairement aux estimations de gaussiennes, on fait ici aucune supposition sur la distribution des données. On considère juste que chaque classe a une densité de probabilité que respecte les échantillons de la vérité terrain. L'estimation de cette densité de probabilité se fait justement grâce à ces échantillons. A chacun de ces échantillons est attribué un noyau, c'est-à-dire une fonction prédifinie qui fait office de densité de probabilité. Ce noyau est le même pour tous les échantillons. La densité de probabilité de la classe devient donc la moyenne de ce noyau appliqué sur chacun des échantillons de la classe. La formule de tout ce blabla est la suivante : \n",
    "\n",
    "$f(x) = \\frac{1}{n} \\sum_{i} \\phi(x-x_{i})$\n",
    "\n",
    "Dans cette magnifique formule, n est le nombre d'échantillons de la classe, $\\phi$ est la fonction noyau, $x_{i}$ est l'échantillon i de la classe, et x est l'échantillon à prédire. Pour le point de vue graphique, faut venir en TP (chaud les graphiques sur Jupyter...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-things",
   "metadata": {},
   "source": [
    "**La question préliminaire :** Alors, les fenêtres de Parzen ? Méthode paramétrique ou non paramétrique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-walter",
   "metadata": {},
   "source": [
    "**_Réponse :_** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-reader",
   "metadata": {},
   "source": [
    "## Partie 1 : Création des noyaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-browse",
   "metadata": {},
   "source": [
    "On va d'abord créer les fonctions de noyau. Ces fonctions prendront en entrée l'échantillon à prédire, un échantillon d'une classe, et un paramètre h."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-castle",
   "metadata": {},
   "source": [
    "**1)** Commençons avec le noyau uniforme ! Le principe est ultra simple : on crée une densité de probabilité uniforme de taille hxh centrée sur l'échantillon de la classe (on est ici dans le cas 2D). Si notre échantillon à prédire se trouve dans cette densité de probabilité (donc dans le carré hxh), la fonction retourne $\\frac{1}{h^{2}}$, sinon la fonction retourne 0. Créez cette fonction pour commencer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de noyau uniforme\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-skirt",
   "metadata": {},
   "source": [
    "Testez votre fonction maintenant avec ces quelques tests unitaires réalisés par mes soins :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-rachel",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test 1 : L'échantillon est dans le noyau\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([2.8,2.9])\n",
    "h = 2\n",
    "val_noyau_uniforme = ...\n",
    "assert val_noyau_uniforme == 0.25, \"Test 1 non fonctionnel\"\n",
    "\n",
    "# Test 2 : L'échantillon n'est pas dans le noyau\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([3.8,2.9])\n",
    "h = 1\n",
    "val_noyau_uniforme = ...\n",
    "assert val_noyau_uniforme == 0, \"Test 2 non fonctionnel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-blast",
   "metadata": {},
   "source": [
    "**2)** Créons un 2ème type de noyau : le noyau gaussien. Il n'est pas aussi simple que l'uniforme, mais ça va encore ;) Ici, comme son nom l'indique, la densité de probabilité est une fonction gaussienne 2D centré sur l'échantillon de la classe et de variance h. La formule du noyau est donc la suivante : \n",
    "\n",
    "$\\phi(x,x_{i}) = \\frac{1}{2\\pi\\sigma^{2}} e^{\\frac{||x-x_{i}||^{2}}{2\\sigma^{2}}}$\n",
    "\n",
    "Ici, $\\sigma$ est la variance, donc h, et x_{i} un échantillon de la classe. \n",
    "\n",
    "Là où on va se simplifier la vie, c'est qu'on n'a pas besoin de la \"réelle\" valeur de la distance, mais juste une valeur pour comparaison (on veut juste attribuer une classe à notre échantillon à prédire, pas obtenir une distance). On va donc garder que la partie exponentielle de la formule ci-dessus.\n",
    "\n",
    "Bon, vous avez toutes les infos, donc créez cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de noyau gaussien\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-relevance",
   "metadata": {},
   "source": [
    "Hop hop hop ! On teste la fonction avant la prochaine étape !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([2.8,2.9])\n",
    "h = 2\n",
    "val_noyau_gaussien = ...\n",
    "assert np.abs(val_noyau_gaussien-0.93)<0.01, \"Test 1 non fonctionnel\"\n",
    "\n",
    "# Test 2\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([3.8,2.9])\n",
    "h = 1\n",
    "val_noyau_gaussien = ...\n",
    "assert np.abs(val_noyau_gaussien-0.33)<0.01, \"Test 2 non fonctionnel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-constant",
   "metadata": {},
   "source": [
    "## Partie 2 : Construction du modèle par fenêtres de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-brighton",
   "metadata": {},
   "source": [
    "**1)** Créez le classifieur par fenêtres de Parzen, une classe python qui hérite de votre classe Modele de base. Dans le constructeur, vous aurez deux nouveaux paramètres : votre fonction de noyau (uniforme ou gaussien), et un paramètre h. La fonction de prédiction calcule la probabilité de l'échantillon à prédire pour chaque classe, qui est la moyenne (ou somme) des densités de probas des noyaux appliqués à chacun des échantillons d'apprentissage de chaque classe.\n",
    "\n",
    "*Note :* La fonction d'apprentissage ici n'est pas vraiment intéressante, puisque il n'y a \"aucun apprentissage\". Maintenant, de mon côté, j'ai utilisé cette fonction pour stocker les échantillons d'apprentissage divisé par classes.\n",
    "\n",
    "*Note 2 :*  Il se peut que votre échantillon à prédire soit très loin de tous les autres échantillons et que vous ayez pour chaque classe un score de 0. Dans ce cas-là, on ne trie pas les classes par score maximum, et on renvoit None à la place de la liste de classes triée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création de la classe de classifieur par fenêtres de Parzen\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-torture",
   "metadata": {},
   "source": [
    "**2)** Testez deux modèles de Parzen (1 avec noyau uniforme, un avec noyau gaussien), sur le jeu de données 1, et avec comme paramètre h=8. Affichez les résultats (top1, top2 et matrice de confusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Tests des modèles de Parzen (uniforme, gaussien) sur le JDD 1, h=8\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-cabinet",
   "metadata": {},
   "source": [
    "**3)** Un deuxième petit test mais cette fois avec un noyau uniforme et un paramètre h=1. Qu'est-ce qui ne va pas avec cette configuration ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Le deuxième petit test\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-october",
   "metadata": {},
   "source": [
    "**_Réponse (analyse du problème) :_** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-eleven",
   "metadata": {},
   "source": [
    "**4)** A partir du problème que vous avez constaté, modifiez votre fonction de calcul de métrique pour prendre en charge les échantillons non classés. Un tel échantillon est donc considéré comme une fausse prédiction (d'un point de vue des scores top1 et top2). Pour ce qui est de la matrice de confusion, on rajoutera une colonne pour tous les échantillons non classés.\n",
    "\n",
    "*Note :* Cette fonction pourra ensuite remplacer celle de base de la classe Modele (TP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création de la classe de classifieur par fenêtres de Parzen, avec la correction sur la fonction de métriques\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-handling",
   "metadata": {},
   "source": [
    "**5)** Re-testez maintenant votre modèle de Parzen uniforme avec h=1 sur le jeu de données 1. Vous devriez constater un nombre significatif de points non classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création du modèle de Parzen uniforme, h=1\n",
    "...\n",
    "\n",
    "# Apprentissage du classifieur avec les données d'apprentissage\n",
    "...\n",
    "\n",
    "# Evaluation du classifieur avec les données d'évaluation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-information",
   "metadata": {},
   "source": [
    "## Partie 3 : Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-journalism",
   "metadata": {},
   "source": [
    "Une question se pose : comment choisis-t-on le paramètre h ?\n",
    "\n",
    "Une première solution serait de tester plusieurs paramètres h sur le jeu d'évaluation. Cette stratégie, c'est un **RED FLAG !!!** \n",
    "En fait, le jeu d'évaluation est uniquement destiné à l'évaluation d'un modèle : A aucun moment, il ne faut ajuster ces paramètres avec ce jeu, mais uniquement ce jeu d'apprentissage. Pourquoi cela ? Car nous souhaitons un modèle qui \"généralise\" bien, c'est-à-dire adapté à notre problème et non au jeu de données. Hors, en adaptant le ou les paramètre(s), on optimise le classifieur sur le jeu de données...\n",
    "\n",
    "Alors, pour optimiser le paramètre h, on va utiliser le jeu d'apprentissage uniquement, et on va utiliser la cross validation. Le principe est simple : on va diviser le jeu d'apprentissage en N dossiers. Ensuite, pour chaque valeur de paramètre, on va faire N tests, avec pour chaque jeu un dossier de validation pour l'évaluation, et les autres dossiers pour l'apprentissage. On fera ensuite une moyenne des scores obtenus (ici, le top1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-suspect",
   "metadata": {},
   "source": [
    "**1)** Ecrivez la fonction de cross validation, qui prendra en entrée N (le nombre de dossiers crées pour la cross validation), les données et labels du jeu d'apprentissage, et la range des valeurs h à tester (h minimum, h maximum et step), ainsi que d'autres paramètres à définir. La fonction retournera la moyenne des scores top1 pour chaque valeur de h testée.\n",
    "\n",
    "*Note :* Faites attention lors de la répartition des données en dossier. Il faut avoir des échantillons de chaque classe dans chaque dossier, sinon, ça va être compliqué..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de cross validation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-siemens",
   "metadata": {},
   "source": [
    "**2)** Testez votre fonction de cross validation à 3 dossiers sur le jeu de données 1 avec un noyau gaussien. Quel est le meilleur h obtenu ? Et quel est la moyenne des top1 avec ce paramètre ?\n",
    "\n",
    "*Note :* On souhaiterait avoir la meilleur valeur de h à une précision de 1 décimale après la virgule. Ayez une stratégie pour éviter de calculer toutes les valeurs possibles, car sinon, ça va être très long ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Cross validation sur le jeu de donnée 1, noyau uniforme\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-piece",
   "metadata": {},
   "source": [
    "**3)** Faites de même maintenant avec les 3 jeux de données et les 2 types de noyau. Vous devriez donc avoir 6 valeurs de h optimisés et 6 scores obtenus sur les dossiers de validation. Remplissez ensuite le tableau avec tous ces résultats.\n",
    "\n",
    "Pour comparaison, je vous donne mes résultats obtenus ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-coach",
   "metadata": {},
   "source": [
    "| Jeu de données / Noyau  | h | top1 |\n",
    "|:-----------------------:|:-:|:----:|\n",
    "| JDD 1 / Uniforme  | 4.2 | 100% |\n",
    "| JDD 1 / Gaussien  | 0.1 | 100% |\n",
    "| JDD 2 / Uniforme  | 5.2 | 94.99% |\n",
    "| JDD 2 / Gaussien  | 1.8 | 94.99% |\n",
    "| JDD 3 / Uniforme  | 4.1 | 74.79% |\n",
    "| JDD 3 / Gaussien  | 2.5 | 75.19% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-feature",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Cross validation sur le jeu de donnée 1, noyau uniforme\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-prior",
   "metadata": {},
   "source": [
    "| Jeu de données / Noyau  | h | top1 |\n",
    "|:-----------------------:|:-:|:----:|\n",
    "| JDD 1 / Uniforme  | 4.2 |  |\n",
    "| JDD 1 / Gaussien  | 0.1 |  |\n",
    "| JDD 2 / Uniforme  | 5.2 |  |\n",
    "| JDD 2 / Gaussien  | 1.8 |  |\n",
    "| JDD 3 / Uniforme  | 4.1 |  |\n",
    "| JDD 3 / Gaussien  | 2.5 |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-report",
   "metadata": {},
   "source": [
    "**4)** Evaluez maitenant vos classifieurs sur les jeux d'évaluation des 3 jeux de données, avec les 2 types de noyaux, et avec les paramètres h optimisés. Reportez les résultats sur le tableau suivant. Les résultats sont-ils en raccord avec ceux obtenus sur les jeux de validations ? Comparez les performances des classifieurs en dissociant l'analyse sur les 3 jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-world",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Evaluation des classifieurs sur les jeux de tests\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-addition",
   "metadata": {},
   "source": [
    "| Jeu de données / Noyau  | h | top1 valid | top1 eval |\n",
    "|:-----------------------:|:-:|:----------:|:---------:|\n",
    "| JDD 1 / Uniforme  | 4.2 |  |  |\n",
    "| JDD 1 / Gaussien  | 0.1 |  |  |\n",
    "| JDD 2 / Uniforme  | 5.2 |  |  |\n",
    "| JDD 2 / Gaussien  | 1.8 |  |  |\n",
    "| JDD 3 / Uniforme  | 4.1 |  |  |\n",
    "| JDD 3 / Gaussien  | 2.5 |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-dodge",
   "metadata": {},
   "source": [
    "**_Réponse :_**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
