{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attended-storage",
   "metadata": {},
   "source": [
    "# TP3 : Fenêtres de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-intake",
   "metadata": {},
   "source": [
    "Maintenant que vous êtes des experts en estimation de gaussiennes, on va découvrir une nouvelle technique pour la classification : les fenêtres de Parzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import progressbar\n",
    "\n",
    "from utils import Model, split_data, read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-hollow",
   "metadata": {},
   "source": [
    "Contrairement aux estimations de gaussiennes, on fait ici aucune supposition sur la distribution des données. On considère juste que chaque classe a une densité de probabilité que respecte les échantillons de la vérité terrain. L'estimation de cette densité de probabilité se fait justement grâce à ces échantillons. A chacun de ces échantillons est attribué un noyau, c'est-à-dire une fonction prédifinie qui fait office de densité de probabilité. Ce noyau est le même pour tous les échantillons. La densité de probabilité de la classe devient donc la moyenne de ce noyau appliqué sur chacun des échantillons de la classe. La formule de tout ce blabla est la suivante : \n",
    "\n",
    "$f(x) = \\frac{1}{n} \\sum_{i} \\phi(x-x_{i})$\n",
    "\n",
    "Dans cette magnifique formule, n est le nombre d'échantillons de la classe, $\\phi$ est la fonction noyau, $x_{i}$ est l'échantillon i de la classe, et x est l'échantillon à prédire. Pour le point de vue graphique, faut venir en TP (chaud les graphiques sur Jupyter...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-brooklyn",
   "metadata": {},
   "source": [
    "**La question préliminaire :** Alors, les fenêtres de Parzen ? Méthode paramétrique ou non paramétrique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-jimmy",
   "metadata": {},
   "source": [
    "**_Réponse :_** C'est une méthode non paramétrique ! Ici, on ne fait AUCUNE supposition sur la distribution des données, c'est avec les échantillons qu'on en fait une estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-mother",
   "metadata": {},
   "source": [
    "## Partie 1 : Création des noyaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-roots",
   "metadata": {},
   "source": [
    "On va d'abord créer les fonctions de noyau. Ces fonctions prendront en entrée l'échantillon à prédire, un échantillon d'une classe, et un paramètre h."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-village",
   "metadata": {},
   "source": [
    "**1)** Commençons avec le noyau uniforme ! Le principe est ultra simple : on crée une densité de probabilité uniforme de taille hxh centrée sur l'échantillon de la classe (on est ici dans le cas 2D). Si notre échantillon à prédire se trouve dans cette densité de probabilité (donc dans le carré hxh), la fonction retourne $\\frac{1}{h^{2}}$, sinon la fonction retourne 0. Créez cette fonction pour commencer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medieval-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de noyau uniforme\n",
    "def noyau_uniforme(A,B,h):\n",
    "    # A et B sont 2 points 2D (x,y)\n",
    "    # Noyau de taille h X h centré au point A\n",
    "    # Si B est dans le noyau, la distance est de 1/h², sinon la distance est de 0\n",
    "    if np.abs(A[0]-B[0])<h/2 and np.abs(A[1]-B[1])<h/2:\n",
    "        return 1/h**2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-rolling",
   "metadata": {},
   "source": [
    "Testez votre fonction maintenant avec ces quelques tests unitaires réalisés par mes soins :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fatal-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1 : L'échantillon est dans le noyau\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([2.8,2.9])\n",
    "h = 2\n",
    "assert noyau_uniforme(A,B,h) == 0.25, \"Test 1 non fonctionnel\"\n",
    "\n",
    "# Test 2 : L'échantillon n'est pas dans le noyau\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([3.8,2.9])\n",
    "h = 1\n",
    "assert noyau_uniforme(A,B,h) == 0, \"Test 2 non fonctionnel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-mount",
   "metadata": {},
   "source": [
    "**2)** Créons un 2ème type de noyau : le noyau gaussien. Il n'est pas aussi simple que l'uniforme, mais ça va encore ;) Ici, comme son nom l'indique, la densité de probabilité est une fonction gaussienne 2D centré sur l'échantillon de la classe et de variance h. La formule du noyau est donc la suivante : \n",
    "\n",
    "$\\phi(x,x_{i}) = \\frac{1}{2\\pi\\sigma^{2}} e^{\\frac{||x-x_{i}||^{2}}{2\\sigma^{2}}}$\n",
    "\n",
    "Ici, $\\sigma$ est la variance, donc h, et x_{i} un échantillon de la classe. \n",
    "\n",
    "Là où on va se simplifier la vie, c'est qu'on n'a pas besoin de la \"réelle\" valeur de la distance, mais juste une valeur pour comparaison (on veut juste attribuer une classe à notre échantillon à prédire, pas obtenir une distance). On va donc garder que la partie exponentielle de la formule ci-dessus.\n",
    "\n",
    "Bon, vous avez toutes les infos, donc créez cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aquatic-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de noyau gaussien\n",
    "def noyau_gaussien(A,B,h):\n",
    "    # A et B sont 2 points 2D (x,y)\n",
    "    # Noyau gaussien de variance h centré au point A\n",
    "    sigma = h\n",
    "    return np.exp(-((A-B).T@(A-B))/(2*(sigma**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-mexican",
   "metadata": {},
   "source": [
    "Hop hop hop ! On teste la fonction avant la prochaine étape !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "activated-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3362164937067334\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([2.8,2.9])\n",
    "h = 2\n",
    "assert np.abs(noyau_gaussien(A,B,h)-0.93)<0.01, \"Test 1 non fonctionnel\"\n",
    "\n",
    "# Test 2\n",
    "A = np.array([2.5,3.6])\n",
    "B = np.array([3.8,2.9])\n",
    "h = 1\n",
    "assert np.abs(noyau_gaussien(A,B,h)-0.33)<0.01, \"Test 2 non fonctionnel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-package",
   "metadata": {},
   "source": [
    "## Partie 2 : Construction du modèle par fenêtres de Parzen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-syndicate",
   "metadata": {},
   "source": [
    "**1)** Créez le classifieur par fenêtres de Parzen, une classe python qui hérite de votre classe Modele de base. Dans le constructeur, vous aurez deux nouveaux paramètres : votre fonction de noyau (uniforme ou gaussien), et un paramètre h. La fonction de prédiction calcule la probabilité de l'échantillon à prédire pour chaque classe, qui est la moyenne (ou somme) des densités de probas des noyaux appliqués à chacun des échantillons d'apprentissage de chaque classe.\n",
    "\n",
    "*Note :* La fonction d'apprentissage ici n'est pas vraiment intéressante, puisque il n'y a \"aucun apprentissage\". Maintenant, de mon côté, j'ai utilisé cette fonction pour stocker les échantillons d'apprentissage divisé par classes.\n",
    "\n",
    "*Note 2 :*  Il se peut que votre échantillon à prédire soit très loin de tous les autres échantillons et que vous ayez pour chaque classe un score de 0. Dans ce cas-là, on ne trie pas les classes par score maximum, et on renvoit None à la place de la liste de classes triée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "military-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création de la classe de classifieur par fenêtres de Parzen\n",
    "class Parzen(Model):\n",
    "    # Définition du constructeur\n",
    "    def __init__(self,classes,noyau='uniforme',h=None):\n",
    "        super(Parzen, self).__init__(classes)\n",
    "        self.h = h\n",
    "        assert noyau in ['uniforme','gaussien']\n",
    "        self.noyau = noyau\n",
    "        if self.noyau == 'uniforme':\n",
    "            self.core_func = noyau_uniforme\n",
    "        else:\n",
    "            self.core_func = noyau_gaussien\n",
    "    \n",
    "    # Définition de la fonction d'apprentissage\n",
    "    def learning(self,app_x,app_y,app_labels):\n",
    "        self.app_points = {}\n",
    "        for classe in self.classes:\n",
    "            ind_lab = app_labels.index[app_labels==classe]\n",
    "            app_x_lab = app_x[ind_lab]\n",
    "            app_y_lab = app_y[ind_lab]\n",
    "            self.app_points[classe]=[app_x_lab,app_y_lab]\n",
    "    \n",
    "    \n",
    "    # Définition de la classe de prédiction\n",
    "    def prediction(self,x,y):\n",
    "        X = np.array([x,y])\n",
    "        classes_dists = np.zeros((len(classes)))\n",
    "        for i,classe in enumerate(classes):\n",
    "            classes_dists[i] = sum([self.core_func(X,pt,self.h) for pt in zip(self.app_points[classe][0],self.app_points[classe][1])])\n",
    "        if np.all(classes_dists==0):\n",
    "            return None\n",
    "        ind_dists = np.argsort(classes_dists)[::-1]\n",
    "        return classes[ind_dists]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-piano",
   "metadata": {},
   "source": [
    "**2)** Testez deux modèles de Parzen (1 avec noyau uniforme, un avec noyau gaussien), sur le jeu de données 1, et avec comme paramètre h=8. Affichez les résultats (top1, top2 et matrice de confusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "parental-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST PARZEN UNIFORME\n",
      "Top 1 :  0.996\n",
      "Top 2 :  0.998\n",
      "Matrice de confusion : \n",
      "    99   0   0   0   1\n",
      "    0 100   0   0   0\n",
      "    0   0 100   0   0\n",
      "    0   0   0 100   0\n",
      "    1   0   0   0  99\n",
      "TEST PARZEN GAUSSIEN\n",
      "Top 1 :  0.996\n",
      "Top 2 :  1.0\n",
      "Matrice de confusion : \n",
      "    98   0   0   0   2\n",
      "    0 100   0   0   0\n",
      "    0   0 100   0   0\n",
      "    0   0   0 100   0\n",
      "    0   0   0   0 100\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Chargement des données tp1 app et dec\n",
    "file_app = f'Archive/data_tp1_app.txt'\n",
    "file_dec = f'Archive/data_tp1_dec.txt'\n",
    "columns_labels = ['label','x','y']\n",
    "data_app = read_data(file_app,columns_labels)\n",
    "data_dec = read_data(file_dec,columns_labels)\n",
    "\n",
    "classes = np.unique(data_app['label'])\n",
    "\n",
    "# Création d'une instance de modèle classifieur de Parzen avec noyau uniforme\n",
    "parzen_uniforme = Parzen(classes,'uniforme',8)\n",
    "\n",
    "# Création d'une instance de modèle classifieur de Parzen avec noyau gaussien\n",
    "parzen_gaussien = Parzen(classes,'gaussien',8)\n",
    "\n",
    "# Apprentissage du classifieur avec les données d'apprentissage\n",
    "app_x = data_app['x']\n",
    "app_y = data_app['y']\n",
    "app_labels = data_app['label']\n",
    "\n",
    "parzen_uniforme.learning(app_x,app_y,app_labels)\n",
    "parzen_gaussien.learning(app_x,app_y,app_labels)\n",
    "\n",
    "# Evaluation du classifieur avec les données d'évaluation\n",
    "dec_x = data_dec['x']\n",
    "dec_y = data_dec['y']\n",
    "dec_labels = data_dec['label']\n",
    "\n",
    "print(\"TEST PARZEN UNIFORME\")\n",
    "top1,top2,CM = parzen_uniforme.test(dec_x,dec_y,dec_labels)\n",
    "\n",
    "print(\"TEST PARZEN GAUSSIEN\")\n",
    "top1,top2,CM = parzen_gaussien.test(dec_x,dec_y,dec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-bermuda",
   "metadata": {},
   "source": [
    "**3)** Un deuxième petit test mais cette fois avec un noyau uniforme et un paramètre h=1. Qu'est-ce qui ne va pas avec cette configuration ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "involved-pendant",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6cfd30da354e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Evaluation du classifieur avec les données d'évaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtop1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparzen_uniforme\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdec_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdec_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\TBD_L3\\utils.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, dec_x, dec_y, dec_labels, print_results)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdec_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdec_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdec_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtop1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdec_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Top 1 : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\TBD_L3\\utils.py\u001b[0m in \u001b[0;36mmetrics\u001b[1;34m(self, gt, pred)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtop2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[0mtop1\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mtop2\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Création du modèle de Parzen uniforme, h=1\n",
    "parzen_uniforme = Parzen(classes,'uniforme',1)\n",
    "\n",
    "# Apprentissage du classifieur avec les données d'apprentissage\n",
    "parzen_uniforme.learning(app_x,app_y,app_labels)\n",
    "\n",
    "# Evaluation du classifieur avec les données d'évaluation\n",
    "top1,top2,CM = parzen_uniforme.test(dec_x,dec_y,dec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-sucking",
   "metadata": {},
   "source": [
    "**_Réponse (analyse du problème) :_** Ici, on a une erreur de type TypeError. On a un objet de type NoneType, alors que ça devrait être une liste de classes triées. Du coup, l'échantillon est non classé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-radius",
   "metadata": {},
   "source": [
    "**4)** A partir du problème que vous avez constaté, modifiez votre fonction de calcul de métrique pour prendre en charge les échantillons non classés. Un tel échantillon est donc considéré comme une fausse prédiction (d'un point de vue des scores top1 et top2). Pour ce qui est de la matrice de confusion, on rajoutera une colonne pour tous les échantillons non classés.\n",
    "\n",
    "*Note :* Cette fonction pourra ensuite remplacer celle de base de la classe Modele (TP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exposed-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création de la classe de classifieur par fenêtres de Parzen\n",
    "class Parzen(Model):\n",
    "    # Définition du constructeur\n",
    "    def __init__(self,classes,noyau='uniforme',h=None):\n",
    "        super(Parzen, self).__init__(classes)\n",
    "        self.h = h\n",
    "        assert noyau in ['uniforme','gaussien']\n",
    "        self.noyau = noyau\n",
    "        if self.noyau == 'uniforme':\n",
    "            self.core_func = noyau_uniforme\n",
    "        else:\n",
    "            self.core_func = noyau_gaussien\n",
    "    \n",
    "    # Définition de la fonction d'apprentissage\n",
    "    def learning(self,app_x,app_y,app_labels):\n",
    "        self.app_points = {}\n",
    "        for classe in self.classes:\n",
    "            ind_lab = app_labels.index[app_labels==classe]\n",
    "            app_x_lab = app_x[ind_lab]\n",
    "            app_y_lab = app_y[ind_lab]\n",
    "            self.app_points[classe]=[app_x_lab,app_y_lab]\n",
    "    \n",
    "    \n",
    "    # Définition de la fonction de prédiction\n",
    "    def prediction(self,x,y):\n",
    "        X = np.array([x,y])\n",
    "        classes_dists = np.zeros((len(classes)))\n",
    "        for i,classe in enumerate(classes):\n",
    "            classes_dists[i] = sum([self.core_func(X,pt,self.h) for pt in zip(self.app_points[classe][0],self.app_points[classe][1])])\n",
    "        if np.all(classes_dists==0):\n",
    "            return None\n",
    "        ind_dists = np.argsort(classes_dists)[::-1]\n",
    "        return classes[ind_dists]\n",
    "    \n",
    "    # Définition de la fonction de métrique qui prend en charge les points non classés.\n",
    "    def metrics(self,gt,pred):\n",
    "        CM = np.zeros((len(self.classes),len(self.classes)+1),dtype=np.uint16)\n",
    "        top1 = 0\n",
    "        top2 = 0\n",
    "        for g,p in zip(gt,pred):\n",
    "            if p is None:\n",
    "                CM[g-1,-1]+=1\n",
    "            else:\n",
    "                if g == p[0]:\n",
    "                    top1+=1\n",
    "                    top2+=1\n",
    "                elif g in p[:2]:\n",
    "                    top2+=1\n",
    "                CM[g-1,p[0]-1]+=1\n",
    "        return top1/len(gt), top2/len(gt), CM\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-confidentiality",
   "metadata": {},
   "source": [
    "**5)** Re-testez maintenant votre modèle de Parzen uniforme avec h=1 sur le jeu de données 1. Vous devriez constater un nombre significatif de points non classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "collectible-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 :  0.87\n",
      "Top 2 :  0.87\n",
      "Matrice de confusion : \n",
      "   83  0  0  0  1 16\n",
      "   0 75  0  0  0 25\n",
      "   0  0 90  0  0 10\n",
      "   0  0  0 94  0  6\n",
      "   0  0  0  0 93  7\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Création du modèle de Parzen uniforme, h=1\n",
    "parzen_uniforme = Parzen(classes,'uniforme',1)\n",
    "\n",
    "# Apprentissage du classifieur avec les données d'apprentissage\n",
    "parzen_uniforme.learning(app_x,app_y,app_labels)\n",
    "\n",
    "# Evaluation du classifieur avec les données d'évaluation\n",
    "top1,top2,CM = parzen_uniforme.test(dec_x,dec_y,dec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-december",
   "metadata": {},
   "source": [
    "## Partie 3 : Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-gallery",
   "metadata": {},
   "source": [
    "Une question se pose : comment choisis-t-on le paramètre h ?\n",
    "\n",
    "Une première solution serait de tester plusieurs paramètres h sur le jeu d'évaluation. Cette stratégie, c'est un **RED FLAG !!!** \n",
    "En fait, le jeu d'évaluation est uniquement destiné à l'évaluation d'un modèle : A aucun moment, il ne faut ajuster ces paramètres avec ce jeu, mais uniquement ce jeu d'apprentissage. Pourquoi cela ? Car nous souhaitons un modèle qui \"généralise\" bien, c'est-à-dire adapté à notre problème et non au jeu de données. Hors, en adaptant le ou les paramètre(s), on optimise le classifieur sur le jeu de données...\n",
    "\n",
    "Alors, pour optimiser le paramètre h, on va utiliser le jeu d'apprentissage uniquement, et on va utiliser la cross validation. Le principe est simple : on va diviser le jeu d'apprentissage en N dossiers. Ensuite, pour chaque valeur de paramètre, on va faire N tests, avec pour chaque jeu un dossier de validation pour l'évaluation, et les autres dossiers pour l'apprentissage. On fera ensuite une moyenne des scores obtenus (ici, le top1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-puppy",
   "metadata": {},
   "source": [
    "**1)** Ecrivez la fonction de cross validation, qui prendra en entrée N (le nombre de dossiers crées pour la cross validation), les données et labels du jeu d'apprentissage, et la range des valeurs h à tester (h minimum, h maximum et step), ainsi que d'autres paramètres à définir. La fonction retournera la moyenne des scores top1 pour chaque valeur de h testée.\n",
    "\n",
    "*Note :* Faites attention lors de la répartition des données en dossier. Il faut avoir des échantillons de chaque classe dans chaque dossier, sinon, ça va être compliqué..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sealed-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de cross validation\n",
    "def cross_validation(N,data_x,data_y,data_labels,model_func,classes,noyau,hmin=0,hmax=10,hstep=1):\n",
    "    # Première étape : on divise les données en N datasets aléatoirement\n",
    "    part = []\n",
    "    for i in range(N):\n",
    "        ids_app = [j for j in range(len(data_x)) if j%N != i]\n",
    "        ids_val = [j for j in range(len(data_x)) if j%N == i]\n",
    "        part.append({'app':[data_x[ids_app],data_y[ids_app],data_labels[ids_app]],\n",
    "                     'val':[data_x[ids_val],data_y[ids_val],data_labels[ids_val]]})\n",
    "\n",
    "\n",
    "    h_results = []\n",
    "    for h in progressbar.progressbar(np.arange(hmin,hmax,hstep)):\n",
    "        if h == 0:\n",
    "            h = 1e-4\n",
    "        h_top1 = []\n",
    "        for i in range(N):\n",
    "            model = model_func(classes,noyau,h)\n",
    "            app_x,app_y,app_labels = part[i]['app']\n",
    "            val_x,val_y,val_labels = part[i]['val']\n",
    "            model.learning(app_x,app_y,app_labels)\n",
    "            top1,__,__ = model.test(val_x,val_y,val_labels,print_results=False)\n",
    "            h_top1.append(top1)\n",
    "        h_results.append((h,np.mean(h_top1)))\n",
    "    return h_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-arbitration",
   "metadata": {},
   "source": [
    "**2)** Testez votre fonction de cross validation à 3 dossiers sur le jeu de données 1 avec un noyau gaussien. Quel est le meilleur h obtenu ? Et quel est la moyenne des top1 avec ce paramètre ?\n",
    "\n",
    "*Note :* On souhaiterait avoir la meilleur valeur de h à une précision de 1 décimale après la virgule. Ayez une stratégie pour éviter de calculer toutes les valeurs possibles, car sinon, ça va être très long ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "reasonable-toronto",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:11 Time:  0:00:11\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:21 Time:  0:00:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Cross validation sur le jeu de donnée 1, noyau uniforme\n",
    "jeu = 1\n",
    "noyau ='gaussien'\n",
    "\n",
    "# Chargement des données tp1 app et dec\n",
    "file_app = f'Archive/data_tp{jeu}_app.txt'\n",
    "file_dec = f'Archive/data_tp{jeu}_dec.txt'\n",
    "columns_labels = ['label','x','y']\n",
    "data_app = read_data(file_app,columns_labels)\n",
    "classes = np.unique(data_app['label'])\n",
    "\n",
    "# Apprentissage du classifieur avec les données d'apprentissage\n",
    "app_x = data_app['x']\n",
    "app_y = data_app['y']\n",
    "app_labels = data_app['label']\n",
    "\n",
    "# 1er test : h => 0-10, pas 1\n",
    "print(\"Test n°1\")\n",
    "h_results = cross_validation(3,app_x,app_y,app_labels,Parzen,classes,noyau,0,10,1)\n",
    "h_max = max([p[1] for p in h_results])\n",
    "h_opti = [h for h in h_results if h[1]==h_max][0][0]\n",
    "\n",
    "# Deuxième test : on test à 0.1 step, entre h_opti -1 et h_opti + 1\n",
    "print(\"Test n°2\")\n",
    "h_results = cross_validation(3,app_x,app_y,app_labels,Parzen,classes,noyau,int(h_opti-1),int(h_opti+1),0.1)\n",
    "h_max = max([p[1] for p in h_results])\n",
    "h_opti = [h for h in h_results if h[1]==h_max][0][0]\n",
    "top1_opti = [h for h in h_results if h[1]==h_max][0][1]\n",
    "print(h_opti)\n",
    "print(top1_opti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-citation",
   "metadata": {},
   "source": [
    "**3)** Faites de même maintenant avec les 3 jeux de données et les 2 types de noyau. Vous devriez donc avoir 6 valeurs de h optimisés et 6 scores obtenus sur les dossiers de validation. Remplissez ensuite le tableau avec tous ces résultats.\n",
    "\n",
    "Pour comparaison, je vous donne mes résultats obtenus ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-delicious",
   "metadata": {},
   "source": [
    "| Jeu de données / Noyau  | h | top1 |\n",
    "|:-----------------------:|:-:|:----:|\n",
    "| JDD 1 / Uniforme  | 4.2 | 100% |\n",
    "| JDD 1 / Gaussien  | 0.1 | 100% |\n",
    "| JDD 2 / Uniforme  | 5.2 | 94.99% |\n",
    "| JDD 2 / Gaussien  | 1.8 | 94.99% |\n",
    "| JDD 3 / Uniforme  | 4.1 | 74.79% |\n",
    "| JDD 3 / Gaussien  | 2.5 | 75.19% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "contained-command",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:07 Time:  0:00:07\n",
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:11 Time:  0:00:11\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:07 Time:  0:00:07\n",
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:11 Time:  0:00:11\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:04 Time:  0:00:04\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:07 Time:  0:00:07\n",
      "N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:11 Time:  0:00:11\n",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:21 Time:  0:00:21\n"
     ]
    }
   ],
   "source": [
    "h_optimisesléter\n",
    "# Cross validation sur le jeu de donnée 1, noyau uniforme\n",
    "h_optimises = {}\n",
    "for jeu in [1,2,3]:\n",
    "    for noyau in ['uniforme','gaussien']:\n",
    "        # Chargement des données tp1 app et dec\n",
    "        file_app = f'Archive/data_tp{jeu}_app.txt'\n",
    "        file_dec = f'Archive/data_tp{jeu}_dec.txt'\n",
    "        columns_labels = ['label','x','y']\n",
    "        data_app = read_data(file_app,columns_labels)\n",
    "        classes = np.unique(data_app['label'])\n",
    "\n",
    "        # Apprentissage du classifieur avec les données d'apprentissage\n",
    "        app_x = data_app['x']\n",
    "        app_y = data_app['y']\n",
    "        app_labels = data_app['label']\n",
    "\n",
    "        # 1er test : h => 0-10, pas 1\n",
    "        print(\"Test n°1\")\n",
    "        h_results = cross_validation(3,app_x,app_y,app_labels,Parzen,classes,noyau,0,10,1)\n",
    "        h_max = max([p[1] for p in h_results])\n",
    "        h_opti = [h for h in h_results if h[1]==h_max][0][0]\n",
    "\n",
    "        # Deuxième test : on test à 0.1 step, entre h_opti -1 et h_opti + 1\n",
    "        print(\"Test n°2\")\n",
    "        h_results = cross_validation(3,app_x,app_y,app_labels,Parzen,classes,noyau,int(h_opti-1),int(h_opti+1),0.1)\n",
    "        h_max = max([p[1] for p in h_results])\n",
    "        h_opti = [h for h in h_results if h[1]==h_max][0][0]\n",
    "        top1_opti = [h for h in h_results if h[1]==h_max][0][1]\n",
    "        h_optimises['{}_{}'.format(jeu,noyau)] = (h_opti,top1_opti)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-field",
   "metadata": {},
   "source": [
    "| Jeu de données / Noyau  | h | top1 |\n",
    "|:-----------------------:|:-:|:----:|\n",
    "| JDD 1 / Uniforme  | 4.2 | 100% |\n",
    "| JDD 1 / Gaussien  | 0.1 | 100% |\n",
    "| JDD 2 / Uniforme  | 5.2 | 94.99% |\n",
    "| JDD 2 / Gaussien  | 1.8 | 94.99% |\n",
    "| JDD 3 / Uniforme  | 4.1 | 74.79% |\n",
    "| JDD 3 / Gaussien  | 2.5 | 75.19% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-devices",
   "metadata": {},
   "source": [
    "**4)** Evaluez maitenant vos classifieurs sur les jeux d'évaluation des 3 jeux de données, avec les 2 types de noyaux, et avec les paramètres h optimisés. Reportez les résultats sur le tableau suivant. Les résultats sont-ils en raccord avec ceux obtenus sur les jeux de validations ? Comparez les performances des classifieurs en dissociant l'analyse sur les 3 jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "tamil-current",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.199999999999999\n",
      "0.1\n",
      "6.199999999999996\n",
      "1.8\n",
      "4.100000000000001\n",
      "0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Evaluation des classifieurs sur les jeux de tests\n",
    "top1_eval = {}\n",
    "for jeu in [1,2,3]:\n",
    "    for noyau in ['uniforme','gaussien']:\n",
    "        h = h_optimises['{}_{}'.format(jeu,noyau)][0]\n",
    "        # Chargement des données tp1 app et dec\n",
    "        file_app = f'Archive/data_tp{jeu}_app.txt'\n",
    "        file_dec = f'Archive/data_tp{jeu}_dec.txt'\n",
    "        columns_labels = ['label','x','y']\n",
    "        data_app = read_data(file_app,columns_labels)\n",
    "        data_dec = read_data(file_dec,columns_labels)\n",
    "        classes = np.unique(data_app['label'])\n",
    "\n",
    "        # Création du modèle\n",
    "        model = Parzen(classes,noyau,h)\n",
    "        \n",
    "        # Apprentissage du classifieur avec les données d'apprentissage\n",
    "        app_x = data_app['x']\n",
    "        app_y = data_app['y']\n",
    "        app_labels = data_app['label']\n",
    "        \n",
    "        model.learning(app_x,app_y,app_labels)\n",
    "\n",
    "        # Evaluation du classifieur avec les données d'évaluation\n",
    "        dec_x = data_dec['x']\n",
    "        dec_y = data_dec['y']\n",
    "        dec_labels = data_dec['label']\n",
    "\n",
    "        top1,top2,CM = model.test(dec_x,dec_y,dec_labels,print_results=False)\n",
    "        top1_eval['{}_{}'.format(jeu,noyau)] = top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "connected-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_uniforme': 0.994,\n",
       " '1_gaussien': 0.992,\n",
       " '2_uniforme': 0.948,\n",
       " '2_gaussien': 0.952,\n",
       " '3_uniforme': 0.714,\n",
       " '3_gaussien': 0.7}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-shell",
   "metadata": {},
   "source": [
    "| Jeu de données / Noyau  | h | top1 valid | top1 eval |\n",
    "|:-----------------------:|:-:|:----------:|:---------:|\n",
    "| JDD 1 / Uniforme  | 4.2 | 100% | 99.40% |\n",
    "| JDD 1 / Gaussien  | 0.1 | 100% | 99.20% |\n",
    "| JDD 2 / Uniforme  | 5.2 | 94.99% | 94.80% |\n",
    "| JDD 2 / Gaussien  | 1.8 | 94.99% | 95.20% |\n",
    "| JDD 3 / Uniforme  | 4.1 | 74.79% | 71.40% |\n",
    "| JDD 3 / Gaussien  | 2.5 | 75.19% | 70.00% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-snowboard",
   "metadata": {},
   "source": [
    "**_Réponse :_** Les résultats en évaluation sont sensiblement les mêmes que ceux en validation, donc les modèles n'ont pas de surapprentissage (hormis ceux sur le jeu de données 3). Les résultats sont quasi parfaits sur le JDD 1, et très bons sur le JDD 2. Pour le JDD 3, c'est toujours compliqué..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-frederick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
