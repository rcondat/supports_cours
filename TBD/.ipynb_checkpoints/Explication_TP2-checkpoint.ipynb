{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rapid-winner",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 1 : Classifieur par distance euclidienne minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-medicaid",
   "metadata": {},
   "source": [
    "Un classifieur par distance euclidienne minimum est un classifieur qui attribuera à un vecteur de caractéristiques x, la classe i pour laquelle la valeur de $(x-\\mu_{i})^{T}(x -\\mu_{i})$ est minimum (où $\\mu_{i}$ est le vecteur contenant la moyenne de chaque composante des vecteurs de la classe i). Maximiser la probabilité d’appartenance revient donc à minimiser cette distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-kingston",
   "metadata": {},
   "source": [
    "Commençons par une première question : le classifieur par distance euclidienne minimum est-il paramétrique ou non-paramétrique ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-brother",
   "metadata": {},
   "source": [
    "**_Réponse :_** Ce classifieur est un classifieur dit paramétrique car l’on fait une hypothèse sur la répartition des données. Ici on fait l’hypothèse que les données suivent une répartition normale et que les caractéristiques du vecteur x ne sont pas corrélées (cas de gaussiennes isotropes). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-geometry",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 2 : Classifieur par distance de Mahalanobis minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-treat",
   "metadata": {},
   "source": [
    "Maintenant, un nouveau classifieur : le classifieur par distance de Mahalanobis minimum. Il est proche de celui développé précedemment, donc il ne devrait pas être trop dûr à développer :D\n",
    "\n",
    "Ce classifieur attribue à un vecteur de caractéristiques x, la classe i pour laquelle la valeur de $(x-\\mu_{i})^{T}\\sum^{(-1)}(x -\\mu_{i})$ est minimum, avec $\\mu_{i}$ le vecteur contenant la moyenne de chaque composante des vecteurs de la classe i, et $\\sum$ la matrice de covariance des composantes des vecteurs de la classe i. Tout comme le classifieur par distance euclidienne miminum, maximiser la probabilité d’appartenance revient à minimiser la distance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
