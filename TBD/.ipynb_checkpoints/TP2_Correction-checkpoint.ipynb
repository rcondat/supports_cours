{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 : Estimation de gaussiennes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui !!! Vous l'attendiez enfin ! Vous allez développer votre premier modèle classifieur ! Une date marquante dans votre vie à graver dans la roche !\n",
    "\n",
    "Au programme de cet événement, deux classifieurs :\n",
    "- un classifieur par distance euclidienne minimum\n",
    "- un classifieur par distance Mahalanobis minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, vous avez déjà implémenter des fonctions utiles lors du 1er TP (lecture des données, séparation des données par classe, visualisation des données, classe Modèle, etc.). Créez un fichier python (attention, pas un Notebook !) contenant toutes les fonctions mentionnées. A l'avenir, vous aurez juste à importer les fonctions en début de Notebook, au lieu de tout réecrire :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# A compléter\n",
    "# Import des fonctions utiles de votre fichier python\n",
    "from utils import Model, split_data, read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 1 : Classifieur par distance euclidienne minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un classifieur par distance euclidienne minimum est un classifieur qui attribuera à un vecteur de caractéristiques x, la classe i pour laquelle la valeur de $(x-\\mu_{i})^{T}(x -\\mu_{i})$ est minimum (où $\\mu_{i}$ est le vecteur contenant la moyenne de chaque composante des vecteurs de la classe i). Maximiser la probabilité d’appartenance revient donc à minimiser cette distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une petite question : le classifieur par distance euclidienne minimum est-il paramétrique ou non-paramétrique ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Réponse :_** Ce classifieur est un classifieur dit paramétrique car l’on fait une hypothèse sur la répartition des données. Ici on fait l’hypothèse que les données suivent une répartition normale et que les caractéristiques du vecteur x ne sont pas corrélées (cas de gaussiennes isotropes). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Tout d'abord, comme vous l'avez pu voir dans la formule, il faut utiliser un vecteur transposé. Ecrivez donc une fonction faite maison pour transposer une matrice 2D ou 1 vecteur 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Implémentation de la fonction de transposition\n",
    "def transpose(mat):\n",
    "    assert mat.ndim>0 and mat.ndim<3, \"Le nombre de dimensions n'est pas bon\"\n",
    "    if mat.ndim == 1:\n",
    "        h = mat.shape[0]\n",
    "        w = 1\n",
    "    elif mat.ndim == 2:\n",
    "        h,w = mat.shape\n",
    "    mat_trans = np.empty((w,h),dtype=mat.dtype)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if mat.ndim == 1:\n",
    "                mat_trans[j,i] = mat[i]\n",
    "            else:\n",
    "                mat_trans[j,i] = mat[i,j]\n",
    "    return mat_trans\n",
    "\n",
    "# Test de votre fonction avec une matrice\n",
    "A = np.random.randint(5,size=(10,10))\n",
    "B = transpose(A)\n",
    "assert np.all(np.transpose(A)==B),\"Nope, c'est pas bon...\"\n",
    "\n",
    "# Test de votre fonction avec un vecteur\n",
    "A = np.random.randint(5,size=(10))\n",
    "B = transpose(A)\n",
    "assert np.all(np.transpose(A)==B), \"Toujours pas...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** On peut maintenant créer notre classifieur ! Créez la classe de classifieur par distance euclidienne minimum via héritage de votre classe Modèle du TP1 et redéfinissez ses fonctions locales.\n",
    "\n",
    "*_Note_ :* Au minimum, vous devriez redéfinir au moins 3 fonctions : la fonction constructeur (pour appeler le constructeur de la classe parent et définir les variable locales), la fonction d'apprentissage du modèle et la fonction de prédiction du modèle. Evidemment, vous pouvez créer de nouvelles fonctions locales dans votre nouvelle classe, c'est vous qui décidez ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création de la classe de classifieur par distance euclidenne minimum\n",
    "class ClassifieurDistMin(Model):\n",
    "    # Définition du constructeur\n",
    "    def __init__(self,classes):\n",
    "        super(ClassifieurDistMin, self).__init__(classes)\n",
    "        self.classes = classes\n",
    "        self.means = {c:None for c in classes}\n",
    "    \n",
    "    # Définition de la fonction d'apprentissage\n",
    "    def learning(self,app_x,app_y,app_labels):\n",
    "        for classe in self.classes:\n",
    "            ind_lab = app_labels.index[app_labels==classe]\n",
    "            app_x_lab = app_x[ind_lab]\n",
    "            app_y_lab = app_y[ind_lab]\n",
    "            self.means[classe] = np.array([np.mean(app_x_lab),np.mean(app_y_lab)])\n",
    "    \n",
    "    # Définition de la classe de calcul de distance\n",
    "    def dist_classe(self,X,classe):\n",
    "        M = self.means[classe]\n",
    "        return (X-M).T@(X-M)\n",
    "    \n",
    "    # Définition de la classe de prédiction\n",
    "    def prediction(self,x,y):\n",
    "        X = np.array([x,y])\n",
    "        distances = [self.dist_classe(X,classe) for classe in self.classes]\n",
    "        indices = np.argsort(distances)\n",
    "        return self.classes[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Le classifieur développé, il est temps de le tester ! \n",
    "\n",
    "Chargez les données app et dec tp1 et stockez les dans des tableaux (ou listes, ou dictionnaires, en fonction de ce que vous avez opté lors du TP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Chargement des données tp1 app et dec\n",
    "file_app = f'Archive/data_tp1_app.txt'\n",
    "file_dec = f'Archive/data_tp1_dec.txt'\n",
    "columns_labels = ['label','x','y']\n",
    "data_app = read_data(file_app,columns_labels)\n",
    "data_dec = read_data(file_dec,columns_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Créez une instance de modèle classifieur par distance minimum maintenant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Création d'une instance de modèle classifieur\n",
    "classes = np.unique(data_app['label'])\n",
    "model = ClassifieurDistMin(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Effectuez l'apprentissage de votre classifieur avec les données d'apprentissages précedemment chargées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Apprentissage du classifieur avec les données d'apprentissage\n",
    "app_x = data_app['x']\n",
    "app_y = data_app['y']\n",
    "app_labels = data_app['label']\n",
    "\n",
    "model.learning(app_x,app_y,app_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Evaluez maintenant votre modèle avec les données d'évaluation précedemment chargées, et affichez les taux de bonne classification en Top1 et Top2, ainsi que la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 :  0.992\n",
      "Top 2 :  1.0\n",
      "Matrice de confusion : \n",
      "    98   0   0   0   2\n",
      "    0 100   0   0   0\n",
      "    0   0  99   1   0\n",
      "    0   0   0 100   0\n",
      "    1   0   0   0  99\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Evaluation du classifieur avec les données d'évaluation\n",
    "dec_x = data_dec['x']\n",
    "dec_y = data_dec['y']\n",
    "dec_labels = data_dec['label']\n",
    "top1,top2,CM = model.test(dec_x,dec_y,dec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** Alors ? Quels sont les résultats obtenus ? Sont-ils satisfaisants ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Réponse :_** Plutôt oui ! 99,2 % de bonne classification en Top1, et 100% en Top2, c'est plutôt bien ! On peut faire mieux cependant, vu que la base de données est plutôt facile..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)** Effectuez les mêmes opérations avec les bases de données tp2 et tp3, affichez et analysez les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONNEES TP2\n",
      "Top 1 :  0.946\n",
      "Top 2 :  0.996\n",
      "Matrice de confusion : \n",
      "   100   0   0   0   0\n",
      "    2  97   1   0   0\n",
      "    0   5  84   1  10\n",
      "    0   0   6  94   0\n",
      "    0   0   2   0  98\n",
      "\n",
      "DONNEES TP3\n",
      "Top 1 :  0.728\n",
      "Top 2 :  0.892\n",
      "Matrice de confusion : \n",
      "   43 17 16 12 12\n",
      "  12 83  3  0  2\n",
      "  16  4 78  2  0\n",
      "  16  0  7 74  3\n",
      "   5  9  0  0 86\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Chargement des données, création, apprentissage et évaluation des modèles pour les BD tp2 et tp3\n",
    "for s in ['tp2','tp3']:\n",
    "    print(f\"\\nDONNEES {s.upper()}\")\n",
    "    file_app = f'Archive/data_{s}_app.txt'\n",
    "    file_dec = f'Archive/data_{s}_dec.txt'\n",
    "    columns_labels = ['label','x','y']\n",
    "    data_app = read_data(file_app,columns_labels)\n",
    "    data_dec = read_data(file_dec,columns_labels)\n",
    "\n",
    "    app_x = data_app['x']\n",
    "    app_y = data_app['y']\n",
    "    app_labels = data_app['label']\n",
    "\n",
    "    dec_x = data_dec['x']\n",
    "    dec_y = data_dec['y']\n",
    "    dec_labels = data_dec['label']\n",
    "    classes = np.unique(data_dec['label'])\n",
    "\n",
    "    model = ClassifieurDistMin(classes)\n",
    "    model.learning(app_x,app_y,app_labels)\n",
    "    top1,top2,CM = model.test(dec_x,dec_y,dec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Réponse :_** Les résultats sont plutôt corrects sur le tp2, malgré quelques erreurs. Pour tp3, c'est plus chaud... Le classifieur a quand même raison la plupart du temps, mais avec beaucoup plus d'erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 2 : Classifieur par distance de Mahalanobis minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, un nouveau classifieur : le classifieur par distance de Mahalanobis minimum. Il est proche de celui développé précedemment, donc il ne devrait pas être trop dûr à développer :D\n",
    "\n",
    "Ce classifieur attribue à un vecteur de caractéristiques x, la classe i pour laquelle la valeur de $(x-\\mu_{i})^{T}\\sum^{(-1)}(x -\\mu_{i})$ est minimum, avec $\\mu_{i}$ le vecteur contenant la moyenne de chaque composante des vecteurs de la classe i, et $\\sum$ la matrice de covariance des composantes des vecteurs de la classe i. Tout comme le classifieur par distance euclidienne miminum, maximiser la probabilité d’appartenance revient à minimiser la distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Avant de se précipiter sur le classifieur, développez une fonction pour calculer la matrice de covariance entre 2 vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Fonction de calcul de la matrice de covariance entre 2 vecteurs\n",
    "def covariance(A,B):\n",
    "    mean_A = np.mean(A)\n",
    "    mean_B = np.mean(B)\n",
    "    Ac = A-mean_A\n",
    "    Bc = B-mean_B\n",
    "    N = A.shape[0]\n",
    "    Avar = (1/(N-1))*(Ac@np.transpose(Ac))\n",
    "    Bvar = (1/(N-1))*(Bc@np.transpose(Bc))\n",
    "    ABcov = (1/(N-1))*(Ac@np.transpose(Bc))\n",
    "    return np.array([[Avar,ABcov],\n",
    "                     [ABcov,Bvar]])\n",
    "\n",
    "# Test de votre fonction\n",
    "A = np.random.randint(5,size=(10))\n",
    "B = np.random.randint(5,size=(10))\n",
    "\n",
    "AB_cov = covariance(A,B)\n",
    "assert np.all(np.abs(AB_cov-np.cov(A,B))<1e-4), \"Ah, c'est pas ça...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** On va avoir également besoin d'une fonction pour inverser une matrice... Développez-là !\n",
    "\n",
    "*_Note :_* On se contentera d'une inversion d'une matrice de taille 2X2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Fonction de calcul de l'inverse d'une matrice\n",
    "\n",
    "def inverse(mat):\n",
    "    assert mat.shape == (2,2), \"Ici, on inverse que les matrice 2X2 !\"\n",
    "    det_mat = mat[0,0]*mat[1,1]-mat[0,1]*mat[1,0]\n",
    "    assert det_mat!=0, \"La matrice n'est pas inversible, déso\"\n",
    "    return (1/det_mat)*np.array([[mat[1,1],-mat[0,1]],\n",
    "                             [-mat[1,0],mat[0,0]]])\n",
    "\n",
    "# Test de votre fonction\n",
    "A = np.array([[1,2],[3,4]])\n",
    "inv_A = inverse(A)\n",
    "print(A)\n",
    "print(inv_A)\n",
    "print(np.linalg.inv(A))\n",
    "assert np.all(np.abs(np.linalg.inv(A)-inv_A)<1e-4), \"Ca marche pas...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Nous avons tous les outils en main ! Définissez votre nouvelle classe de classifieur par distance de Mahalanobis minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# Définition de la classe de classifieur par distance de Mahalanobis minimum\n",
    "class ClassifieurDistMahalanobis(Model):\n",
    "    def __init__(self,classes):\n",
    "        super(ClassifieurDistMahalanobis, self).__init__(classes)\n",
    "        self.classes = classes\n",
    "        self.means = {c:None for c in classes}\n",
    "        self.covMat = {c:None for c in classes}\n",
    "    def learning(self,app_x,app_y,app_labels):\n",
    "        for classe in self.classes:\n",
    "            ind_lab = app_labels.index[app_labels==classe]\n",
    "            app_x_lab = app_x[ind_lab]\n",
    "            app_y_lab = app_y[ind_lab]\n",
    "            self.means[classe] = np.array([np.mean(app_x_lab),np.mean(app_y_lab)])\n",
    "            self.covMat[classe] = np.linalg.inv(np.cov(app_x_lab,app_y_lab))\n",
    "    \n",
    "    def dist_classe(self,X,classe):\n",
    "        M = self.means[classe]\n",
    "        Z = self.covMat[classe]\n",
    "        return (X-M).T@Z@(X-M)\n",
    "    \n",
    "    def prediction(self,x,y):\n",
    "        X = np.array([x,y])\n",
    "        distances = [self.dist_classe(X,classe) for classe in self.classes]\n",
    "        indices = np.argsort(distances)\n",
    "        return self.classes[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Pour chaque base de données (tp1,tp2 et tp3), testez votre nouveau classifieur (apprentissage + évaluation) et affichez les métriques. Analysez vos résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONNEES TP1\n",
      "Top 1 :  0.996\n",
      "Top 2 :  0.998\n",
      "Matrice de confusion : \n",
      "    99   0   0   0   1\n",
      "    0 100   0   0   0\n",
      "    0   0 100   0   0\n",
      "    0   0   0 100   0\n",
      "    0   0   0   1  99\n",
      "\n",
      "DONNEES TP2\n",
      "Top 1 :  0.954\n",
      "Top 2 :  0.994\n",
      "Matrice de confusion : \n",
      "   99  0  1  0  0\n",
      "   0 95  5  0  0\n",
      "   0  4 91  2  3\n",
      "   0  0  3 97  0\n",
      "   0  0  5  0 95\n",
      "\n",
      "DONNEES TP3\n",
      "Top 1 :  0.694\n",
      "Top 2 :  0.87\n",
      "Matrice de confusion : \n",
      "   55 18 12  6  9\n",
      "  15 80  2  0  3\n",
      "  19  4 76  1  0\n",
      "  39  0  7 53  1\n",
      "  10  7  0  0 83\n"
     ]
    }
   ],
   "source": [
    "# A compléter\n",
    "# Chargement des données, création, apprentissage et évaluation des modèles pour les BD tp1, tp2 et tp3\n",
    "for s in ['tp1','tp2','tp3']:\n",
    "    print(f\"\\nDONNEES {s.upper()}\")\n",
    "    file_app = f'Archive/data_{s}_app.txt'\n",
    "    file_dec = f'Archive/data_{s}_dec.txt'\n",
    "    columns_labels = ['label','x','y']\n",
    "    data_app = read_data(file_app,columns_labels)\n",
    "    data_dec = read_data(file_dec,columns_labels)\n",
    "\n",
    "    app_x = data_app['x']\n",
    "    app_y = data_app['y']\n",
    "    app_labels = data_app['label']\n",
    "\n",
    "    dec_x = data_dec['x']\n",
    "    dec_y = data_dec['y']\n",
    "    dec_labels = data_dec['label']\n",
    "    classes = np.unique(data_dec['label'])\n",
    "\n",
    "    model = ClassifieurDistMahalanobis(classes)\n",
    "    model.learning(app_x,app_y,app_labels)\n",
    "    top1,top2,CM = model.test(dec_x,dec_y,dec_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Réponse :_** Les performances sur les BD tp1 et tp2 sont plutôt bonnes malgré quelques erreurs par-ci par-là... Pour le tp3, ça se complique beaucoup plus..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Il est l'heure de comparer les 2 classifieurs développés. Regroupez les métriques Top1 et Top2 obtenues par les 2 classifieurs sur chaque base de données, placez-les dans un ou plusieurs tableaux récapitulatifs et affichez les (avec des labels en index et en colonne). Comparez les performances des classifieurs en dissociant l'analyse sur les 3 jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dist_Euclid_tp1</th>\n",
       "      <td>0.992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist_Mahana_tp1</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist_Euclid_tp2</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist_Mahana_tp2</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist_Euclid_tp3</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dist_Mahana_tp3</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  top1   top2\n",
       "Dist_Euclid_tp1  0.992      1\n",
       "Dist_Mahana_tp1  0.996  0.998\n",
       "Dist_Euclid_tp2  0.946  0.996\n",
       "Dist_Mahana_tp2  0.954  0.994\n",
       "Dist_Euclid_tp3  0.728  0.892\n",
       "Dist_Mahana_tp3  0.694   0.87"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "# A compléter\n",
    "# Création du tableau récapitulatif\n",
    "recap = pd.DataFrame(index=['{}_{}'.format(classif,bd) for bd,classif in product(['tp1','tp2','tp3'],['Dist_Euclid','Dist_Mahana'])],columns=['top1','top2'])\n",
    "\n",
    "for s in ['tp1','tp2','tp3']:\n",
    "    file_app = f'Archive/data_{s}_app.txt'\n",
    "    file_dec = f'Archive/data_{s}_dec.txt'\n",
    "    columns_labels = ['label','x','y']\n",
    "    data_app = read_data(file_app,columns_labels)\n",
    "    data_dec = read_data(file_dec,columns_labels)\n",
    "\n",
    "    app_x = data_app['x']\n",
    "    app_y = data_app['y']\n",
    "    app_labels = data_app['label']\n",
    "\n",
    "    dec_x = data_dec['x']\n",
    "    dec_y = data_dec['y']\n",
    "    dec_labels = data_dec['label']\n",
    "    classes = np.unique(data_dec['label'])\n",
    "    for name_classif,Classifieur in zip(['Dist_Euclid','Dist_Mahana'],[ClassifieurDistMin,ClassifieurDistMahalanobis]):\n",
    "        model = Classifieur(classes)\n",
    "        model.learning(app_x,app_y,app_labels)\n",
    "        top1,top2,CM = model.test(dec_x,dec_y,dec_labels,display=False)\n",
    "        recap['top1'][f\"{name_classif}_{s}\"] = top1\n",
    "        recap['top2'][f\"{name_classif}_{s}\"] = top2\n",
    "\n",
    "recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Réponse :_** Au vu des résultats du tableau, on voit que le classifieur par distance euclidienne minimum performe mieux sur chaque métrique et sur base de donnée par rapport au classifieur par distance de Mahanalobis minimum. Cela est encore plus flagrant sur la BD tp3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
